{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPc47S3XjZp-",
        "outputId": "4dd3a4a2-3a45-4c25-da44-aeb2f461c17f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent (LLM): Hello! You can ask me anything. Type 'exit' to quit.\n",
            "Agent (LLM): There is no standard word \"farmised.\"  It's likely a misspelling or a newly coined word.  To understand its meaning, we need more context.  Where did you encounter this word?  What was the surrounding text or conversation?\n",
            "\n",
            "It could be a misspelling of words like:\n",
            "\n",
            "* **Farm-raised:**  Referring to animals or produce raised on a farm.\n",
            "* **Furnished:**  Meaning something is equipped with furniture.\n",
            "* **Familiarized:**  Meaning to become accustomed to something.\n",
            "\n",
            "Providing more context will help determine the intended meaning.\n",
            "Agent (LLM): When someone is hungry, they experience a feeling of emptiness or craving in their stomach.  This is triggered by the body's need for energy and nutrients.  The specific sensations and reactions can vary depending on the person and how long they've gone without food, ranging from mild grumbling to intense pangs of hunger and even lightheadedness.  Beyond the physical sensations, hunger can also impact mood, concentration, and energy levels.\n",
            "Agent (LLM): Okay, Ruth.  I understand. I will address you as Ruth from now on.\n",
            "Agent (LLM): You're welcome!  Is there anything I can help you with today?\n",
            "Agent (LLM): That's great to hear! I'm glad you're feeling happy today.  Is there anything in particular that's making you happy?  I'd love to hear about it if you'd like to share.\n",
            "Agent (LLM): That's a cute little poem!  It paints a charming picture of a robot learning to program.  Here are a few ways we could expand on it:\n",
            "\n",
            "**Option 1:  Continuing the story**\n",
            "\n",
            "> A little robot in the hall,\n",
            "> Learning Python, having a ball,\n",
            "> Loops and functions, lines of code,\n",
            "> Through the campus it happily strode.\n",
            "> It met a student, bright and keen,\n",
            "> Who showed it tricks, a coding scene.\n",
            "> With newfound knowledge, shining bright,\n",
            "> The robot programmed day and night.\n",
            ">  It built a program, sleek and grand,\n",
            "> To help the students understand\n",
            "> The mysteries of code's design,\n",
            "> A helpful bot, truly divine!\n",
            "\n",
            "\n",
            "**Option 2:  Focusing on a specific challenge**\n",
            "\n",
            "> A little robot in the hall,\n",
            "> Learning Python, having a ball,\n",
            "> Loops and functions, lines of code,\n",
            "> Through the campus it happily strode.\n",
            "> But then a problem it did face,\n",
            "> A tricky bug, it couldn't trace.\n",
            "> With careful thought and patient hand,\n",
            "> It debugged the code, and took a stand.\n",
            ">  The error vanished, bright and clear,\n",
            "> A victory shout, a joyful cheer!\n",
            "\n",
            "\n",
            "**Option 3:  Making it more descriptive**\n",
            "\n",
            "> A little robot, chrome and bright,\n",
            "> In the echoing hall, a wondrous sight,\n",
            "> Learning Python, a happy hum,\n",
            "> Loops and functions, overcoming some\n",
            "> Tricky challenges, line by line,\n",
            "> Through the bustling campus, a coding shrine,\n",
            "> It happily strode, its circuits ablaze,\n",
            "> A future programmer in a coding maze.\n",
            "\n",
            "\n",
            "Which direction would you like to explore further?  Or perhaps you have another idea?\n"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "# --- Initialize Gemini client ---\n",
        "client = genai.Client(api_key=\"YOUR_API_KEY\")  # Replace with your actual key\n",
        "\n",
        "# Optional: system prompt to guide the assistant (can remove if you want fully general responses)\n",
        "system_prompt = (\n",
        "    \"You are an AI assistant. You can answer any question, tell stories, help with coding, or be creative. \"\n",
        "    \"Always try to respond clearly and helpfully.\"\n",
        ")\n",
        "\n",
        "# --- Function to send prompt to Gemini ---\n",
        "def get_llm_response(user_message, system_prompt=None):\n",
        "    model_name = \"gemini-1.5-flash\"\n",
        "    try:\n",
        "        if system_prompt:\n",
        "            prompt = f\"[SYSTEM]\\n{system_prompt}\\n\\n[USER]\\n{user_message}\"\n",
        "        else:\n",
        "            prompt = user_message\n",
        "\n",
        "        # Correct client call\n",
        "        response = client.models.generate_content(\n",
        "            model=model_name,\n",
        "            contents=prompt\n",
        "        )\n",
        "\n",
        "        # Extract response safely\n",
        "        if hasattr(response, \"text\"):\n",
        "            return response.text.strip()\n",
        "        elif hasattr(response, \"candidates\"):\n",
        "            return response.candidates[0].content.parts[0].text.strip()\n",
        "        else:\n",
        "            return \"No response text available.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"Sorry, I am unable to connect at the moment.\"\n",
        "\n",
        "# --- Conversation loop ---\n",
        "print(\"Agent (LLM): Hello! You can ask me anything. Type 'exit' to quit.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Agent (LLM): Goodbye!\")\n",
        "        break\n",
        "    response = get_llm_response(user_input, system_prompt=system_prompt)\n",
        "    print(\"Agent (LLM):\", response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QSmADRGsYtA"
      },
      "source": [
        "Class Discussion\n",
        "\n",
        "1) Interact with the LLM agent. What are the key differences between\n",
        "its repsonses and the rule-based agents from earlier labs?\n",
        "\n",
        "Rule-based agents are predictable, limited, and rigid because they can only follow pre-defined rules while LLM agents are flexible, creative, and more human-like.\n",
        "\n",
        "2) Give the LLM agent a prompt that requires it to be creative, like \"Write a short poem about a robot.\" What happens? How\n",
        "would you implement this with a rule-based expert system?\n",
        "\n",
        "LLM agents can come up with new and creative answers, like writing a poem about a robot, while rule-based systems can only give the answers they were specifically programmed to give and cannot handle anything new.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PouPU-vVsvJv",
        "outputId": "fa91c11c-911e-487d-9f31-815fa786f8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent (TA): Hello! I am your AI Teaching Assistant. How can I help you with your labs?\n",
            "Type 'exit' to end the conversation.\n",
            "Agent (TA): KeyErrors in Python dictionaries happen when you try to access a key that doesn't exist.  The best way to fix this is to check if the key exists *before* accessing it.\n",
            "\n",
            "Here are a few ways to handle this:\n",
            "\n",
            "**1. Using the `in` operator:**\n",
            "\n",
            "```python\n",
            "my_dict = {\"a\": 1, \"b\": 2}\n",
            "\n",
            "if \"c\" in my_dict:\n",
            "    value = my_dict[\"c\"]\n",
            "    print(value)\n",
            "else:\n",
            "    print(\"Key 'c' not found!\")\n",
            "```\n",
            "\n",
            "**2. Using the `get()` method:**\n",
            "\n",
            "The `get()` method allows you to specify a default value if the key is not found:\n",
            "\n",
            "```python\n",
            "my_dict = {\"a\": 1, \"b\": 2}\n",
            "\n",
            "value = my_dict.get(\"c\", 0)  # Returns 0 if \"c\" is not found\n",
            "print(value)\n",
            "\n",
            "value = my_dict.get(\"a\", 0) # Returns the value associated with \"a\"\n",
            "print(value)\n",
            "```\n",
            "\n",
            "**3. Using a `try-except` block:**\n",
            "\n",
            "This is useful for more complex scenarios where you might want to handle the error differently:\n",
            "\n",
            "```python\n",
            "my_dict = {\"a\": 1, \"b\": 2}\n",
            "\n",
            "try:\n",
            "    value = my_dict[\"c\"]\n",
            "    print(value)\n",
            "except KeyError:\n",
            "    print(\"Key 'c' not found!  Handling the error gracefully.\")\n",
            "```\n",
            "\n",
            "Remember to choose the method that best suits your needs and coding style. Keep up the great work!\n",
            "Agent (TA): I can't answer questions about movies, but I'd be happy to help you with your Python coding assignments!  Let me know what you're working on.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3122710724.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Agent (TA): Goodbye!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from google import genai\n",
        "\n",
        "# --- Initialize Gemini client ---\n",
        "client = genai.Client(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an AI assistant for a university course on AI and Machine Learning. \"\n",
        "    \"Your goal is to help students with their Python coding labs. \"\n",
        "    \"Be concise, encouraging, and provide code examples when relevant. \"\n",
        "    \"Do not answer questions outside of this domain.\"\n",
        ")\n",
        "\n",
        "def get_llm_response(user_message, system_prompt=None):\n",
        "    model_name = \"gemini-1.5-flash\"\n",
        "    try:\n",
        "        if system_prompt:\n",
        "            prompt = f\"[SYSTEM]\\n{system_prompt}\\n\\n[USER]\\n{user_message}\"\n",
        "        else:\n",
        "            prompt = user_message\n",
        "\n",
        "        response = client.models.generate_content(\n",
        "            model=model_name,\n",
        "            contents=prompt\n",
        "        )\n",
        "\n",
        "        if hasattr(response, \"text\"):\n",
        "            return response.text.strip()\n",
        "        elif hasattr(response, \"candidates\"):\n",
        "            return response.candidates[0].content.parts[0].text.strip()\n",
        "        else:\n",
        "            return \"No response text available.\"\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return \"Sorry, I am unable to connect at the moment.\"\n",
        "\n",
        "print(\"Agent (TA): Hello! I am your AI Teaching Assistant. How can I help you with your labs?\")\n",
        "print(\"Type 'exit' to end the conversation.\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Agent (TA): Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # The new agent call now includes the system prompt\n",
        "    response = get_llm_response(user_input, system_prompt=system_prompt)\n",
        "    print(\"Agent (TA):\", response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkOIKIy7vMHp"
      },
      "source": [
        "1) Test the new agent. Ask it a question about AI labs, like \"How do\n",
        "I fix a KeyError in Python?\" Then, ask it a question outside its\n",
        "domain, like \"What's the best movie?\" What is the difference in its\n",
        "behavior?\n",
        "\n",
        "When I asked about Python labs, it gave helpful answers, but when I asked about movies, it refused because that was outside its role.\n",
        "\n",
        "2) Explain the role of the system_prompt . How does it act as the agent's \"moral compass\" or \"mission statement\"?\n",
        "\n",
        "The system_prompt acts like the agent’s rulebook or mission statement, telling it what to focus on and how to behave.\n",
        "\n",
        "3) Brainstorm some other roles or personalities you could give this agent just by changing the systemprompt (e.g., a creative writer, fact-checker, a grumpy robot).\n",
        "\n",
        "\n",
        "By changing the system\\_prompt, the agent can take on many different roles or personalities. For example, it could be a creative writer that tells stories or poems, a strict fact-checker that only gives verified information, a grumpy robot that answers correctly but sounds annoyed, a motivational coach that encourages students, a friendly tutor that explains things simply, a tech reviewer, a travel guide, or a customer support agent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj9lnH9UwVpq",
        "outputId": "2e24c033-c6f9-4093-e6a6-8e6ec386334a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting feedparser\n",
            "  Using cached feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.181.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=6e8ab16ebadc6353940ba29ae6ca006c9c2a064ef75b862035eb92e1c2e6b8dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.12 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pandas requests feedparser google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqpUXKesXXcG",
        "outputId": "419a4bf7-3cfa-4e42-ba6c-ea80bf57edf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVLiHIVNZVIR",
        "outputId": "fcb5a8fc-6d41-422c-c844-f8dea12e35a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=d02e2cade9198ab7d2473c8b4bc78650fb1b5f4ffce34572073fba94a5a3e221\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.12 sgmllib3k-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install feedparser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpefdMcL4T1L",
        "outputId": "54d37206-3165-4c12-ed5d-4a81035f2430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are no events listed for today, 2025-09-22.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import requests\n",
        "import feedparser\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "\n",
        "CITY = \"Uppsala\"\n",
        "today = date.today()\n",
        "weather_report = \"partly cloudy, 18°C\"\n",
        "\n",
        "# Parse RSS feed\n",
        "rss = feedparser.parse(\n",
        "    requests.get(f\"http://allevents.in/{CITY}/RSS\", timeout=15).text\n",
        ")\n",
        "\n",
        "rows = [\n",
        "    {\n",
        "        \"title\": e.get(\"title\", \"\"),\n",
        "        \"description\": e.get(\"summary\", \"\"),\n",
        "        \"date\": e.get(\"published\", e.get(\"updated\", \"\")),\n",
        "    }\n",
        "    for e in rss.entries\n",
        "]\n",
        "\n",
        "rss_str = pd.DataFrame(rows).to_csv(index=False)\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "prompt = (\n",
        "    \"You are an events organizer. \"\n",
        "    f\"Today is {today}. The weather today is {weather_report}. \"\n",
        "    \"Suggest me one and only one event to do today based on the events listed here:\\n\"\n",
        "    f\"{rss_str}\\n\"\n",
        "    \"If there is nothing happening today, do not suggest me anything. \"\n",
        "    \"Tell me, briefly, when and where the event is happening (in 20 words). \"\n",
        "    \"Explain why it's suitable today (in 20 words), and suggest what I should wear (in 20 words).\"\n",
        ")\n",
        "\n",
        "resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
        "\n",
        "# Clean up Markdown bold if present\n",
        "text = re.sub(r\"\\*\\*([^*]+)\\*\\*\", r\"\\1\", (resp.text or \"\")).strip()\n",
        "\n",
        "print(text or \"No suitable event today.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j87UEM8gW5vF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU5s-sr91aqb",
        "outputId": "6b7dec2c-d15e-4e2e-b480-5969b28b7db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent ready. Type 'exit' to quit.\n",
            "You: exit\n",
            "Agent: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import requests\n",
        "from google import genai\n",
        "client = genai.Client(api_key=\"YOUR_API_KEY\")\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are an AI assistant for an AI/ML course. \"\n",
        "    \"If the user asks to solve a maze path, call the maze solver tool \"\n",
        "    \"(POST /solve on the lab 7 service) and summarize the result clearly.\"\n",
        ")\n",
        "def call_gemini(system_prompt, user_message):\n",
        "    prompt = f\"[SYSTEM]\\n{system_prompt}\\n\\n[USER]\\n{user_message}\"\n",
        "    resp = client.models.generate_content(model=\"gemini-2.5-flash\", contents=prompt)\n",
        "    text = re.sub(r\"\\*\\*([^*]+)\\*\\*\", r\"\\1\", (resp.text or \"\")).strip()\n",
        "    return text\n",
        "def solve_maze(start, end, algorithm=\"bfs\"):\n",
        "    url = \"http://127.0.0.1:5000/solve?explain=true\"\n",
        "    body = {\"start\": start, \"end\": end, \"algorithm\": algorithm}\n",
        "    r = requests.post(url, json=body, timeout=10)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "def parse_solve(line: str):\n",
        "    parts = line.strip().split()\n",
        "    if len(parts) < 3 or parts[0].lower() != \"solve\":\n",
        "        return None\n",
        "    def to_pair(token):\n",
        "        a, b = token.split(\",\")\n",
        "        return [int(a), int(b)]\n",
        "    start = to_pair(parts[1])\n",
        "    end = to_pair(parts[2])\n",
        "    algo = parts[3].lower() if len(parts) > 3 else \"bfs\"\n",
        "    if algo not in {\"bfs\", \"dfs\"}:\n",
        "        algo = \"bfs\"\n",
        "    return {\"start\": start, \"end\": end, \"algorithm\": algo}\n",
        "print(\"Agent ready. Type 'exit' to quit.\")\n",
        "while True:\n",
        "    user = input(\"You: \").strip()\n",
        "    if user.lower() in {\"exit\", \"quit\"}:\n",
        "        print(\"Agent: Goodbye!\")\n",
        "        break\n",
        "    task = parse_solve(user)\n",
        "    if task:\n",
        "        try:\n",
        "            result = solve_maze(task[\"start\"], task[\"end\"], task[\"algorithm\"])\n",
        "            print(\"Agent:\", result.get(\"explanation\") or f\"Path length {result['length']} using {result['algorithm'].upper()}.\")\n",
        "        except requests.HTTPError as e:\n",
        "            print(\"Agent: solver error:\", getattr(e.response, \"text\", str(e)))\n",
        "        except Exception as e:\n",
        "            print(\"Agent: tool call failed:\", e)\n",
        "        continue\n",
        "    print(\"Agent:\", call_gemini(SYSTEM_PROMPT, user))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydNODBuI5f_I"
      },
      "source": [
        "1) Why is explain=true valuable when an LLM is the consumer?\n",
        "\n",
        "Improves transparency, making it easier to explain the result to a user, LLM summaries the solution.\n",
        "\n",
        "2) What risks or limitations arise from relying on a microservice for\n",
        "problem-solving?\n",
        "\n",
        "Downtime because LLM can’t get answers if the service fails.\n",
        "latency which may result in solw responses\n",
        "\n",
        "\n",
        "3) How does this lab illustrate “orchestration” in AI systems?\n",
        "\n",
        "It shows how an AI system coordinates multiple components to solve a problems, The LLM interprets the user’s request and then decides what to do with the request. The maze-solving microservice performs  in helping solving the maze.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
